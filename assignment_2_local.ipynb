{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e2f774f-1136-4f3e-8c50-574d512906de",
   "metadata": {},
   "source": [
    "<a name = Section1></a>\n",
    "#### **1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36fe16ef-a6d6-41cf-a729-5602df1717fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                                 # Importing for panel data analysis\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np                                                  # Importing package numpys (For Numerical Python)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt                                     # Importing pyplot interface of matplotlib\n",
    "import seaborn as sns                                               # Importing seaborn library for interactive visualization\n",
    "%matplotlib inline\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import math\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings                                                     # Importing warning to disable runtime warnings\n",
    "warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86dbd0d5-4894-4dc2-8e22-4f3b95a0dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of    Country  Year Sex\n",
      "0  Albania  2009   m\n",
      "1  Albania  2009   m\n",
      "2  Albania  2010   m\n",
      "3  Albania  2011   m\n",
      "4  Albania  2011   m\n",
      "5  Albania  2012   f\n",
      "6   Russia  2010   f\n",
      "7   Russia  2012   f\n",
      "8    India  2009   f\n",
      "9    India  2010   f>\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "##DataFrame for unit testing\n",
    "country_name_ls = ['Albania'] *6 + ['Russia']*2 + ['India']*2\n",
    "year_ls = ['2009', '2009','2010', '2011', '2011', '2012', '2010', '2012', '2009', '2010']\n",
    "# sex_ls = ['m']*4 + ['f']*2 + ['m'] + ['f']*3\n",
    "sex_ls = ['m']*5 + ['f']*5\n",
    "test_df = pd.DataFrame()\n",
    "test_df['Country'] = country_name_ls\n",
    "test_df['Year'] = year_ls\n",
    "test_df['Sex'] = sex_ls\n",
    "print(test_df.info)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf074d8f-2248-4d31-ba3d-8caa0154719b",
   "metadata": {},
   "source": [
    "<a name = Section1></a>\n",
    "#### **2. Data Acquisition and Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e47576-bae7-488b-b651-caad366f1678",
   "metadata": {},
   "source": [
    "Lets analyze the dataset and identify what attributes require generalization/categorization before we perform BUC on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7481b94-5be2-43e9-b78d-9cb4040cdfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (27820, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex          age  suicides_no  population  \\\n",
       "0  Albania  1987    male  15-24 years           21      312900   \n",
       "1  Albania  1987    male  35-54 years           16      308000   \n",
       "2  Albania  1987  female  15-24 years           14      289700   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year   gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987           NaN          2156624900   \n",
       "1               5.19  Albania1987           NaN          2156624900   \n",
       "2               4.83  Albania1987           NaN          2156624900   \n",
       "\n",
       "   gdp_per_capita ($)    generation  \n",
       "0                 796  Generation X  \n",
       "1                 796        Silent  \n",
       "2                 796  Generation X  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(f'./data/master.xlsx') # Load the Excel dataset\n",
    "print('Shape of the dataset:', data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da7e14-44fb-43c3-9d5a-f6338aefb11a",
   "metadata": {},
   "source": [
    "- We have 27820 records and 12 attributes.\n",
    "- In our records, we have variety of data including nominal data, binomial data, numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7872d5-899a-4534-937f-9ebc62bcce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27820 entries, 0 to 27819\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   country             27820 non-null  object \n",
      " 1   year                27820 non-null  int64  \n",
      " 2   sex                 27820 non-null  object \n",
      " 3   age                 27820 non-null  object \n",
      " 4   suicides_no         27820 non-null  int64  \n",
      " 5   population          27820 non-null  int64  \n",
      " 6   suicides/100k pop   27820 non-null  float64\n",
      " 7   country-year        27820 non-null  object \n",
      " 8   HDI for year        8364 non-null   float64\n",
      " 9    gdp_for_year ($)   27820 non-null  int64  \n",
      " 10  gdp_per_capita ($)  27820 non-null  int64  \n",
      " 11  generation          27820 non-null  object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() # Display basic information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5249ec2-ef64-49b6-b6fa-c61a463dddf2",
   "metadata": {},
   "source": [
    "Checking for:\n",
    "1. duplicate values in rows - delete duplicate rows\n",
    "2. missing values in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "241e217a-fb6b-4ae4-8260-7141ce9576e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, year, sex, age, suicides_no, population, suicides/100k pop, country-year, HDI for year,  gdp_for_year ($) , gdp_per_capita ($), generation]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = data[data.duplicated()] # Selecting duplicate rows except first occurrence based on all columns\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f12f07-e6fa-4a58-8547-9269bb0a9ebf",
   "metadata": {},
   "source": [
    "- It means there are no duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae9ba97c-9c19-4093-94f2-33d0c7ec1a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country                   0\n",
      "year                      0\n",
      "sex                       0\n",
      "age                       0\n",
      "suicides_no               0\n",
      "population                0\n",
      "suicides/100k pop         0\n",
      "country-year              0\n",
      "HDI for year          19456\n",
      " gdp_for_year ($)         0\n",
      "gdp_per_capita ($)        0\n",
      "generation                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff73097-646f-429b-b324-9fd8a73da348",
   "metadata": {},
   "source": [
    "- As we can observe HDI has got 19,456 null values, out of total 27,820 entries. Given, more than half of the entries having NULL values, let's discount this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae1c8b09-1774-4921-a9bc-562ed8679a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['HDI for year'], axis=1, inplace=True)   # Remove the mentioned column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9862504e-1638-4bc1-a5d3-c21345738005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'sex', 'age', 'suicides_no', 'population',\n",
       "       'suicides/100k pop', 'country-year', ' gdp_for_year ($) ',\n",
       "       'gdp_per_capita ($)', 'generation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns # remaining columns in our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d0285-d742-4751-8c75-ad5a32b6293b",
   "metadata": {},
   "source": [
    "<a name = Section2></a>\n",
    "#### **3. Data Analysis and AOI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392215e5-e5aa-40d8-8ac3-452423f66d7f",
   "metadata": {},
   "source": [
    "Now, let's one by one, analyze the 11 dimensions and determine for which dimensions, we need to perform Attribute Oriented Induction (AOI) for generalization/categorization.\n",
    "\n",
    "Data generalization summarizes data by replacing relatively low-level values with higher-level concepts, or by reducing the number of dimensions to summarize data in concept space involving fewer dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b362f451-a8ac-4b77-8742-333046bfcffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in coloumn country:\n",
      " ['Albania' 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Aruba' 'Australia'\n",
      " 'Austria' 'Azerbaijan' 'Bahamas' 'Bahrain' 'Barbados' 'Belarus' 'Belgium'\n",
      " 'Belize' 'Bosnia and Herzegovina' 'Brazil' 'Bulgaria' 'Cabo Verde'\n",
      " 'Canada' 'Chile' 'Colombia' 'Costa Rica' 'Croatia' 'Cuba' 'Cyprus'\n",
      " 'Czech Republic' 'Denmark' 'Dominica' 'Ecuador' 'El Salvador' 'Estonia'\n",
      " 'Fiji' 'Finland' 'France' 'Georgia' 'Germany' 'Greece' 'Grenada'\n",
      " 'Guatemala' 'Guyana' 'Hungary' 'Iceland' 'Ireland' 'Israel' 'Italy'\n",
      " 'Jamaica' 'Japan' 'Kazakhstan' 'Kiribati' 'Kuwait' 'Kyrgyzstan' 'Latvia'\n",
      " 'Lithuania' 'Luxembourg' 'Macau' 'Maldives' 'Malta' 'Mauritius' 'Mexico'\n",
      " 'Mongolia' 'Montenegro' 'Netherlands' 'New Zealand' 'Nicaragua' 'Norway'\n",
      " 'Oman' 'Panama' 'Paraguay' 'Philippines' 'Poland' 'Portugal'\n",
      " 'Puerto Rico' 'Qatar' 'Republic of Korea' 'Romania' 'Russian Federation'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and Grenadines'\n",
      " 'San Marino' 'Serbia' 'Seychelles' 'Singapore' 'Slovakia' 'Slovenia'\n",
      " 'South Africa' 'Spain' 'Sri Lanka' 'Suriname' 'Sweden' 'Switzerland'\n",
      " 'Thailand' 'Trinidad and Tobago' 'Turkey' 'Turkmenistan' 'Ukraine'\n",
      " 'United Arab Emirates' 'United Kingdom' 'United States' 'Uruguay'\n",
      " 'Uzbekistan']\n",
      "---------------------------------------------------------\n",
      "Number of unique values: 101\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in coloumn country:\\n\", data[\"country\"].unique())\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"country\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a671d-1cd7-4ebc-8533-b04c088c89b3",
   "metadata": {},
   "source": [
    "- We will use the values of 'country' dimension as it is, because it is already in the highest-level of concept hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c59d67cc-9b24-4261-bb1c-4f15372694f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in coloumn year:\n",
      " [1987 1988 1989 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002\n",
      " 2003 2004 2005 2006 2007 2008 2009 2010 1985 1986 1990 1991 2012 2013\n",
      " 2014 2015 2011 2016]\n",
      "--------------------------------------------\n",
      "Number of unique values: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in coloumn year:\\n\", data[\"year\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"year\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48feeb-115b-4652-b64e-b5f1d26ad918",
   "metadata": {},
   "source": [
    "- We will use the values of 'year' dimension as it has 32 distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef1a84ad-d925-4906-9099-56d6719a5dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in coloumn sex:\n",
      " ['male' 'female']\n",
      "--------------------------------------------\n",
      "Number of unique values: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in coloumn sex:\\n\", data[\"sex\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"sex\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b556553-513a-4473-ab56-028489365cd3",
   "metadata": {},
   "source": [
    "- We will use the values of 'sex' attribute/dimension as it is because it is already generalized, having two distinct values of the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f042464-4e2d-4b3e-894d-de8f6b2eab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in coloumn age:\n",
      " ['15-24 years' '35-54 years' '75+ years' '25-34 years' '55-74 years'\n",
      " '5-14 years']\n",
      "--------------------------------------------\n",
      "Number of unique values: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in coloumn age:\\n\", data[\"age\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"age\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6295aef-3873-4a33-a65c-00f83aade194",
   "metadata": {},
   "source": [
    "- We will use the values of 'age' dimension as it is because it is already characterized by six distinct values of the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76b63f93-32af-48d1-b8b1-d3b55c89cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in coloumn suicide_no:\n",
      " [  21   16   14 ... 5503 4359 2872]\n",
      "--------------------------------------------\n",
      "Number of unique values: 2084\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in coloumn suicide_no:\\n\", data[\"suicides_no\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"suicides_no\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b430c2af-8f75-4642-8c77-18d50c9bba8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27820.000000\n",
       "mean       242.574407\n",
       "std        902.047917\n",
       "min          0.000000\n",
       "25%          3.000000\n",
       "50%         25.000000\n",
       "75%        131.000000\n",
       "max      22338.000000\n",
       "Name: suicides_no, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"suicides_no\"].describe()    # describe the values of the suicides_no attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7536191d-0c48-41ac-a0eb-affa7d7619b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "suicides_no\n",
       "0       4281\n",
       "1       1539\n",
       "2       1102\n",
       "3        867\n",
       "4        696\n",
       "        ... \n",
       "2158       1\n",
       "525        1\n",
       "2297       1\n",
       "5241       1\n",
       "2872       1\n",
       "Name: count, Length: 2084, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"suicides_no\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a01da-da1d-49fb-b38a-206a83d4236a",
   "metadata": {},
   "source": [
    "- We can derive from the describe() that, the minimum number of suicides are 0. The maximum number of suicide value is 22338.\n",
    "At 25th percentile, the suicide value is 3. This means that 25 percent of data that lies below this 25th percentile point will have value equal to or less than 3.\n",
    "- At 50th percentile, the suicide value is 25. This means half of the data points below 50th percentile point will have value equal to or less than 25. For the high-level description purpose, we can label all those values as `low_suicide_range`.\n",
    "- At 75th percentile, the suicide value is 131. This means that 75% of the data points that lies below this 75th percentile point will have value equal to or less than 131. For the high-level description purpose, we can label all those values above `low_suicide_range` and below the value at 75th percentile as `medium_suicide_range`.\n",
    "- Similarly, the maximum suicide number reported is 22338. All values that lie between 75th percentile value to the maximum reported value can be termed as `high_suicide_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7366535b-abd4-4d58-8392-b9f6cddd365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "      <th>suicides_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "      <td>low_suicides_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "      <td>low_suicides_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year   sex          age  population  suicides/100k pop  \\\n",
       "0  Albania  1987  male  15-24 years      312900               6.71   \n",
       "1  Albania  1987  male  35-54 years      308000               5.19   \n",
       "\n",
       "  country-year   gdp_for_year ($)   gdp_per_capita ($)    generation  \\\n",
       "0  Albania1987          2156624900                 796  Generation X   \n",
       "1  Albania1987          2156624900                 796        Silent   \n",
       "\n",
       "       suicides_range  \n",
       "0  low_suicides_range  \n",
       "1  low_suicides_range  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the labels and conditions\n",
    "conditions = [\n",
    "    (data['suicides_no'] <= data['suicides_no'].quantile(0.5)),\n",
    "    (data['suicides_no'] > data['suicides_no'].quantile(0.5)) & (data['suicides_no'] <= data['suicides_no'].quantile(0.75)),\n",
    "    (data['suicides_no'] > data['suicides_no'].quantile(0.75))\n",
    "]\n",
    "\n",
    "labels = ['low_suicides_range', 'medium_suicides_range', 'high_suicides_range']\n",
    "\n",
    "# Create a new column with the labels\n",
    "data['suicides_range'] = np.select(conditions, labels, default='unknown')\n",
    "data.drop(['suicides_no'], axis=1, inplace=True)   # Remove the column 'suicides_no' because we are using 'suicides_range' in place of that.\n",
    "# Display the first few rows of the DataFrame with the new column\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d0ce0c8-2a07-4974-a65d-1a91be084b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column population:\n",
      " [ 312900  308000  289700 ... 2762158 2631600 1438935]\n",
      "--------------------------------------------\n",
      "Number of unique values: 25564\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in column population:\\n\", data[\"population\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"population\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286a120-48ee-4db0-8989-ffb39344bef4",
   "metadata": {},
   "source": [
    "- \"population\" can't be used directly. Need to perform AOI to create higher-level descriptions or categories for numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ae67545-4cc9-4548-83fb-1ac8f239bf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       27820.000000\n",
       "mean      1844793.617398\n",
       "std       3911779.441756\n",
       "min           278.000000\n",
       "25%         97498.500000\n",
       "50%        430150.000000\n",
       "75%       1486143.250000\n",
       "max      43805214.000000\n",
       "Name: population, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"population\"].describe().apply(lambda x: format(x, 'f')) # Suppress Scientific Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef2a1256-e997-4081-a439-59537daf7345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population\n",
       "24000      20\n",
       "26900      13\n",
       "20700      12\n",
       "22000      12\n",
       "4900       11\n",
       "           ..\n",
       "3282478     1\n",
       "3953119     1\n",
       "5745824     1\n",
       "8448839     1\n",
       "1438935     1\n",
       "Name: count, Length: 25564, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"population\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394cddce-4080-4d74-ab6e-d6352e878b0d",
   "metadata": {},
   "source": [
    "- We can derive from the describe() that, the minimum reported population is 278. The maximum reported population is 43805214.\n",
    "- At 25th percentile, the reported population value is 97498.5. This means that 25 percent of data that lies below this 25th percentile point will have value equal to or less than 97498.\n",
    "- At 50th percentile, the population value is 430150. This means half of the data points below 50th percentile point will have value equal to or less than 430150.\n",
    "- At 75th percentile, the population value is 1486143.25. This means that 75% of the data points that lies below this 75th percentile point will have value equal to or less than 1486143.\n",
    "- For the high-level description purpose:\n",
    "    - we can label all those values that lie between 0 and 25th percentile value as `low_population_range`.\n",
    "    - all the values that lie between 25th percentile value and 75th percentile value as `medium_population_range`.\n",
    "    - all values that lie between 75th percentile value to the maximum reported value can be termed as `high_population_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89cb677c-18f2-4d36-9b8c-2346451f10de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "      <th>suicides_range</th>\n",
       "      <th>population_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "      <td>low_suicides_range</td>\n",
       "      <td>medium_population_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "      <td>low_suicides_range</td>\n",
       "      <td>medium_population_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year   sex          age  suicides/100k pop country-year  \\\n",
       "0  Albania  1987  male  15-24 years               6.71  Albania1987   \n",
       "1  Albania  1987  male  35-54 years               5.19  Albania1987   \n",
       "\n",
       "    gdp_for_year ($)   gdp_per_capita ($)    generation      suicides_range  \\\n",
       "0          2156624900                 796  Generation X  low_suicides_range   \n",
       "1          2156624900                 796        Silent  low_suicides_range   \n",
       "\n",
       "          population_range  \n",
       "0  medium_population_range  \n",
       "1  medium_population_range  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the labels and conditions\n",
    "conditions = [\n",
    "    (data['population'] <= data['population'].quantile(0.25)),\n",
    "    (data['population'] > data['population'].quantile(0.25)) & (data['population'] <= data['population'].quantile(0.75)),\n",
    "    (data['population'] > data['population'].quantile(0.75))\n",
    "]\n",
    "\n",
    "labels = ['low_population_range', 'medium_population_range', 'high_population_range']\n",
    "\n",
    "# Create a new column with the labels\n",
    "data['population_range'] = np.select(conditions, labels, default='unknown')\n",
    "data.drop(['population'], axis=1, inplace=True)   # Remove the column 'population' because we are using 'population_range' in place of that.\n",
    "# Display the first few rows of the DataFrame with the new column\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab410499-ae96-40fa-b3f5-a1dad1fe28a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suicides/100k pop\n",
      "0.00     4281\n",
      "0.29       72\n",
      "0.32       69\n",
      "0.34       55\n",
      "0.37       52\n",
      "         ... \n",
      "46.73       1\n",
      "41.47       1\n",
      "61.03       1\n",
      "28.25       1\n",
      "26.61       1\n",
      "Name: count, Length: 5298, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"suicides/100k pop\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f61e6827-85ed-4485-b16b-d3648f0c4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the column \"suicides/100k pop\":\n",
      " [ 6.71  5.19  4.83 ... 47.86 40.75 26.61]\n",
      "Number of unique values: 5298\n",
      "--------------------------------------------\n",
      "Unique values in the column \"country-year\":\n",
      " ['Albania1987' 'Albania1988' 'Albania1989' ... 'Uzbekistan2012'\n",
      " 'Uzbekistan2013' 'Uzbekistan2014']\n",
      "Number of unique values: 2321\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in the column \\\"suicides/100k pop\\\":\\n\", data[\"suicides/100k pop\"].unique())\n",
    "print(\"Number of unique values:\", data[\"suicides/100k pop\"].nunique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Unique values in the column \\\"country-year\\\":\\n\", data[\"country-year\"].unique())\n",
    "print(\"Number of unique values:\", data[\"country-year\"].nunique())\n",
    "print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3303f6-c453-4c37-82df-ad92d495c9b6",
   "metadata": {},
   "source": [
    "- As we are already using 'population' and 'suicides_no' attributes in their generalized form, we can remove the dimension \"suicides/100k pop\" from our dataset.\n",
    "- Similarly, we are using distinct values in 'country' and 'year' dimension, therefore, we will drop the dimension 'country-year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4efef144-6aef-48c2-9f31-edfccae23511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['suicides/100k pop'], axis=1, inplace=True)   # Remove the mentioned column\n",
    "data.drop(['country-year'], axis=1, inplace=True)   # Remove the mentioned column\n",
    "data.drop(['gdp_per_capita ($)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c974b26-1b8a-4b22-9d26-a0ca1ac5aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             27820.000000\n",
       "mean       445580969025.726624\n",
       "std       1453609985940.912109\n",
       "min            46919625.000000\n",
       "25%          8985352832.000000\n",
       "50%         48114688201.000000\n",
       "75%        260202429150.000000\n",
       "max      18120714000000.000000\n",
       "Name:  gdp_for_year ($) , dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\" gdp_for_year ($) \"].describe().apply(lambda x: format(x, 'f')) # Suppress Scientific Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d15d76-8f74-41ab-af5c-4df3a43df13d",
   "metadata": {},
   "source": [
    "- We can derive from the describe() that, the minimum reported gdp_per_year value is 46,919,625\\\\$. The maximum reported population is 18,120,714,000,000\\\\$.\n",
    "- At 25th percentile, the reported gdp_per_year value is 8,985,352,832\\\\$. This means that 25 percent of data that lies below this 25th percentile point will have value equal to or less than 8,985,352,832\\\\$.\n",
    "- At 50th percentile, the gdp_per_year value is 48,114,688,201\\\\$. This means half of the data points below 50th percentile point will have value equal to or less than 48,114,688,201\\\\$.\n",
    "- At 75th percentile, the gdp_per_year value is 260,202,429,150\\\\$. This means that 75\\% of the data points that lies below this 75th percentile point will have value equal to or less than 260,202,429,150\\\\$. \n",
    "- For the high-level description purpose:\n",
    "    - we can label all those values that lie between 0 and 25th percentile value as `low_income_range`.\n",
    "    - all the values that lie between 25th percentile value and 75th percentile value as `medium_income_range`.\n",
    "    - all values that lie between 75th percentile value to the maximum reported value can be termed as `high_income_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a244244-5b77-4695-b70d-8a061ae388d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>generation</th>\n",
       "      <th>suicides_range</th>\n",
       "      <th>population_range</th>\n",
       "      <th>gdp_per_year_income_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>Generation X</td>\n",
       "      <td>low_suicides_range</td>\n",
       "      <td>medium_population_range</td>\n",
       "      <td>low_income_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>Silent</td>\n",
       "      <td>low_suicides_range</td>\n",
       "      <td>medium_population_range</td>\n",
       "      <td>low_income_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year   sex          age    generation      suicides_range  \\\n",
       "0  Albania  1987  male  15-24 years  Generation X  low_suicides_range   \n",
       "1  Albania  1987  male  35-54 years        Silent  low_suicides_range   \n",
       "\n",
       "          population_range gdp_per_year_income_range  \n",
       "0  medium_population_range          low_income_range  \n",
       "1  medium_population_range          low_income_range  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the labels and conditions\n",
    "conditions = [\n",
    "    (data[' gdp_for_year ($) '] <= data[' gdp_for_year ($) '].quantile(0.25)),\n",
    "    (data[' gdp_for_year ($) '] > data[' gdp_for_year ($) '].quantile(0.25)) & (data[' gdp_for_year ($) '] <= data[' gdp_for_year ($) '].quantile(0.75)),\n",
    "    (data[' gdp_for_year ($) '] > data[' gdp_for_year ($) '].quantile(0.75))\n",
    "]\n",
    "\n",
    "labels = ['low_income_range', 'medium_income_range', 'high_income_range']\n",
    "\n",
    "# Create a new column with the labels\n",
    "data['gdp_per_year_income_range'] = np.select(conditions, labels, default='unknown')\n",
    "data.drop([' gdp_for_year ($) '], axis=1, inplace=True)   # Remove the column 'gdp+per_year ($)' because we are using 'gdp_per_year_income_range' in place of that.\n",
    "# Display the first few rows of the DataFrame with the new column\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79ab6f56-3ccb-41f7-9dd6-59502a654324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation\n",
      "Generation X       6408\n",
      "Silent             6364\n",
      "Millenials         5844\n",
      "Boomers            4990\n",
      "G.I. Generation    2744\n",
      "Generation Z       1470\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"generation\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7654c187-4686-4b4e-9dbf-69fce1de5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:\n",
      " ['Generation X' 'Silent' 'G.I. Generation' 'Boomers' 'Millenials'\n",
      " 'Generation Z']\n",
      "--------------------------------------------\n",
      "Number of unique values: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values:\\n\", data[\"generation\"].unique())\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Number of unique values:\", data[\"generation\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae2f327-ec22-430d-be92-6fa83bb91f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of           country  year     sex          age  gdp_per_capita ($)  \\\n",
      "0         Albania  1987    male  15-24 years                 796   \n",
      "1         Albania  1987    male  35-54 years                 796   \n",
      "2         Albania  1987  female  15-24 years                 796   \n",
      "3         Albania  1987    male    75+ years                 796   \n",
      "4         Albania  1987    male  25-34 years                 796   \n",
      "...           ...   ...     ...          ...                 ...   \n",
      "27815  Uzbekistan  2014  female  35-54 years                2309   \n",
      "27816  Uzbekistan  2014  female    75+ years                2309   \n",
      "27817  Uzbekistan  2014    male   5-14 years                2309   \n",
      "27818  Uzbekistan  2014  female   5-14 years                2309   \n",
      "27819  Uzbekistan  2014  female  55-74 years                2309   \n",
      "\n",
      "            generation         suicides_range         population_range  \\\n",
      "0         Generation X     low_suicides_range  medium_population_range   \n",
      "1               Silent     low_suicides_range  medium_population_range   \n",
      "2         Generation X     low_suicides_range  medium_population_range   \n",
      "3      G.I. Generation     low_suicides_range     low_population_range   \n",
      "4              Boomers     low_suicides_range  medium_population_range   \n",
      "...                ...                    ...                      ...   \n",
      "27815     Generation X  medium_suicides_range    high_population_range   \n",
      "27816           Silent     low_suicides_range  medium_population_range   \n",
      "27817     Generation Z  medium_suicides_range    high_population_range   \n",
      "27818     Generation Z  medium_suicides_range    high_population_range   \n",
      "27819          Boomers     low_suicides_range  medium_population_range   \n",
      "\n",
      "      gdp_per_year_income_range  \n",
      "0              low_income_range  \n",
      "1              low_income_range  \n",
      "2              low_income_range  \n",
      "3              low_income_range  \n",
      "4              low_income_range  \n",
      "...                         ...  \n",
      "27815       medium_income_range  \n",
      "27816       medium_income_range  \n",
      "27817       medium_income_range  \n",
      "27818       medium_income_range  \n",
      "27819       medium_income_range  \n",
      "\n",
      "[27820 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e92266f-5fd8-441d-9eb4-7e8d07c8b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unnecessary variabels after Preprocessing stesps\n",
    "del conditions, duplicate, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb06d96-89e2-4938-9a31-1ab1721eae0f",
   "metadata": {},
   "source": [
    "<a name = Section4></a>\n",
    "#### **4. BUC Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18f66bd-b07c-47cf-a6be-bc84b8ffbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DataFrame for unit testing\n",
    "country_name_ls = ['Albania'] *4 + ['Russia']*2 + ['Albania']*2 + ['India']*2\n",
    "year_ls = ['2009', '2009','2010', '2011', '2011', '2012', '2010', '2012', '2009', '2010']\n",
    "sex_ls = ['m']*4 + ['f']*2 + ['m'] + ['f']*3\n",
    "test_df = pd.DataFrame()\n",
    "test_df['Country'] = country_name_ls\n",
    "test_df['Year'] = year_ls\n",
    "test_df['Sex'] = sex_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5188bf1-2560-40d5-9e9d-30fa6c3a78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_df:\n",
    "  '''\n",
    "  Class to preprocess DataFrame\n",
    "  '''\n",
    "  def encode_attributes(self, input_df, column_indices):\n",
    "    transformed_dicts_ls = []\n",
    "    transformed_df = input_df.copy(deep = True)\n",
    "    column_names = transformed_df.columns.tolist()\n",
    "    print(f\"{column_names = }\")\n",
    "    for col_iter in column_indices:\n",
    "      temp_dict = {}\n",
    "      temp_key = 0\n",
    "      temp_ls = []\n",
    "      column_name = column_names[col_iter]\n",
    "      for col in transformed_df.iloc[:,col_iter].tolist():\n",
    "        if col not in [*temp_dict.keys()]:\n",
    "          temp_dict[col] = temp_key\n",
    "          temp_key += 1\n",
    "        temp_ls.append(temp_dict[col])\n",
    "      dict_inv = {v:k for k,v in temp_dict.items()}\n",
    "      transformed_dicts_ls.append(dict_inv)\n",
    "      transformed_df[column_name] = temp_ls\n",
    "    return transformed_df, transformed_dicts_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5733c2da-62a2-44a5-9dc1-9089e8b43430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUC implementation\n",
    "class buc:\n",
    "    '''\n",
    "    Class for implementing BUC\n",
    "    '''\n",
    "    def __init__(self, df, column_enc_dicts_ls, minsup):\n",
    "        self.numDims = df.shape[1]\n",
    "        self.cardinality = []\n",
    "        self.minsup = minsup\n",
    "        self.output_df = None\n",
    "        self.datacounts = [[]] * df.shape[1]\n",
    "        self.attribute_ls = [\"*\"] * df.shape[1]\n",
    "        self.debug_counter = 0\n",
    "        self.output_dict = {}\n",
    "        self.column_enc_dicts_ls = column_enc_dicts_ls\n",
    "\n",
    "    def counting_sort(self, array_a, df_idx_ls):\n",
    "      '''\n",
    "      Inputs \n",
    "      array_a: List to be sorted\n",
    "      df_idx_ls: Index list corresponding to the array_a. For example: DataFrame indices corresponding to array_a.\n",
    "      Output\n",
    "      idx_ls: Order in which df_idx_ls should be arranged so that array_a is in the sorted order.\n",
    "      '''\n",
    "      array_c = [0]*(max(array_a) + 1)\n",
    "      idx_ls = [-1] * (len(array_a))\n",
    "\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{array_c = }\")\n",
    "      for i in range(0, len(array_a)):\n",
    "        array_c[array_a[i]] += 1\n",
    "\n",
    "      for i in range(0, len(array_c) - 1):\n",
    "        array_c[i+1] = array_c[i] + array_c[i+1]\n",
    "\n",
    "      for i in range(len(array_a) - 1, -1, -1):\n",
    "        array_c[array_a[i]] = array_c[array_a[i]] - 1\n",
    "        idx = array_c[array_a[i]]\n",
    "        idx_ls[idx] = df_idx_ls[i]\n",
    "\n",
    "      # idx_ls = [i + min_idx for i in idx_ls]\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{idx_ls = }\")\n",
    "      return idx_ls\n",
    "\n",
    "\n",
    "    def partition(self, input_df, d, bigc):\n",
    "        '''\n",
    "        Implements partitioning logic i.e sorts the input dataframe and populates self.datacounts\n",
    "        Inputs:\n",
    "        input_df: Input DataFrame\n",
    "        d: column number based on which sorting is performed\n",
    "        Output:\n",
    "        input_df: DataFrame which is sorted according to the specified column\n",
    "        '''\n",
    "        #Sorting the dataframe\n",
    "        temp_counter_dict = {}\n",
    "        sorted_idx = self.counting_sort(input_df.iloc[:,d].tolist(), input_df.index.tolist())\n",
    "        input_df = input_df.reindex(sorted_idx)\n",
    "        #Populating self.datacounts\n",
    "        for attribute in input_df.iloc[:,d].tolist():\n",
    "            temp_counter_dict[attribute] = temp_counter_dict.get(attribute, 0) + 1\n",
    "        self.datacounts[d] = [*temp_counter_dict.values()]\n",
    "        # self.datacounts[d] = input_df.iloc[:,d].value_counts().tolist()\n",
    "        # print(f\"{self.datacounts = }\")\n",
    "        return input_df\n",
    "\n",
    "    def buc_implementation(self, input, dim):\n",
    "        '''\n",
    "        Function to implement BUC as indicated in the original paper. \n",
    "        Populates self.output_dict which is the output dictionary.\n",
    "        NOTE:All the variable names are exactly as indicated in the original paper.\n",
    "        Input\n",
    "        input: Input DataFrame\n",
    "        dim: Starting column for performing aggregation\n",
    "        '''\n",
    "        self.debug_counter += 1\n",
    "        # print(f\"iter: {self.debug_counter - 1}\")\n",
    "        # print(f\"Aggregate: {input.shape[0]}\")\n",
    "        if tuple(self.attribute_ls) in [*self.output_dict.keys()]:\n",
    "          print(f\"Error!!\")\n",
    "        self.output_dict[tuple(self.attribute_ls)] = input.shape[0]\n",
    "        # if self.debug_counter == 12:\n",
    "          # return \n",
    "        # print(f\"{dim = }\")\n",
    "        for d in range(dim, self.numDims,1):\n",
    "            bigc = input.iloc[:,d].nunique()\n",
    "            # print(f\"{d= }, {bigc=}\")\n",
    "            # print(f\"Input before partitioning: {input}\")\n",
    "            input = self.partition(input, d, bigc)\n",
    "            # print(f\"Input after partitioning on {d}: {input}\")\n",
    "            # print(f\"{self.datacounts = }\")\n",
    "            k = 0\n",
    "            for i in range(0, bigc, 1):\n",
    "                # print(f\"################Inside i loop######################\")\n",
    "                # print(f\"{d = }, {i = }\")\n",
    "                # print(f\"{self.datacounts = }\")\n",
    "                smallc = self.datacounts[d][i]\n",
    "                # print(f\"{smallc = }\")\n",
    "                if smallc >= self.minsup:\n",
    "                    # print(f\"**********************Inside if condition***********************\")\n",
    "                    # print(f\"k:{k},  d:{d}\")\n",
    "                    # print(f\"Attribute: {input.iloc[k,d]}\")\n",
    "                    # print(f\"{transformed_dicts[d] = }\")\n",
    "                    self.attribute_ls[d] = self.column_enc_dicts_ls[d][input.iloc[k,d]]\n",
    "                    self.buc_implementation(input.iloc[k:k+smallc,:], dim=d+1)\n",
    "                    # if self.debug_counter == 12:\n",
    "                      # return\n",
    "                    # print(f\"d inside if condition: {d}\")\n",
    "                    # print(f\"******************************************************************\")\n",
    "                k += smallc\n",
    "            # print(f\"#################################################################\")\n",
    "            # print(f\"ALL:\")\n",
    "            # print(f\"k: {k}, d:{d}\")\n",
    "            self.attribute_ls[d] = \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4582f75f-c4f4-441f-a966-f02b4fffd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_merge_sort_implementation(chunk_paths, d, iteration_num, index_dict, file_path):\n",
    "    sorted_chunk_paths = []\n",
    "    index_ls = copy.deepcopy([*index_dict.values()])\n",
    "    output_len_ls = copy.deepcopy([*index_dict.values()])\n",
    "    index_ls = [len(i) for i in index_ls]\n",
    "    output_len_ls = [len(i) for i in output_len_ls]\n",
    "    # print(f\"{index_ls = }, {output_len_ls = }\")\n",
    "    output_len_idx = 0\n",
    "    for i_iter, chunk_path in enumerate(chunk_paths):\n",
    "        # print(f\"{chunk_path = }\")\n",
    "        chunk_df = pd.read_pickle(chunk_path)\n",
    "        if i_iter == 0:\n",
    "            df_columns = chunk_df.columns\n",
    "        # print(f\"{chunk_df = }\")\n",
    "        chunk_df_ls = chunk_df.values.tolist()\n",
    "        # print(f\"{chunk_df_ls = }\")\n",
    "        chunk_df_ls.sort(key = lambda x: (x[d]))\n",
    "        # print(f\"{chunk_df_ls = }\")\n",
    "        sorted_chunk_path = f\"./sorted_{chunk_path.split('/')[-1].split('.pkl')[0]}\"\n",
    "        sorted_chunk_df = pd.DataFrame(chunk_df_ls, columns=df_columns)\n",
    "        # print(f\"{sorted_chunk_df = }\")\n",
    "        sorted_chunk_df.to_pickle(sorted_chunk_path)\n",
    "        sorted_chunk_paths.append(sorted_chunk_path)\n",
    "\n",
    "    # Merge sorted chunks\n",
    "    output_ls = []\n",
    "    idxs_ls = [0] * len(chunk_paths)\n",
    "    input_ls = []\n",
    "    min_idx = -1\n",
    "    debug_counter = 0\n",
    "    sorted_chunks_path_cpy = copy.deepcopy(sorted_chunk_paths)\n",
    "    while True:\n",
    "        #First iteration\n",
    "        if min_idx == -1:\n",
    "            for sorted_chunk_path in sorted_chunks_path_cpy:\n",
    "                df = pd.read_pickle(sorted_chunk_path)\n",
    "                input_ls.append(df.values.tolist()[idxs_ls[i_iter]])\n",
    "        else:\n",
    "            try:\n",
    "                # print(f\"{sorted_chunks_path_cpy = }\")\n",
    "                # print(f\"{min_idx = }\")\n",
    "                # print(f\"{idxs_ls = }\")\n",
    "                df = pd.read_pickle(sorted_chunks_path_cpy[min_idx])\n",
    "                # print(f\"{df = }\")\n",
    "                input_ls.insert(min_idx, df.values.tolist()[idxs_ls[min_idx]])\n",
    "                # input_arr_debug = np.array(input_ls)\n",
    "                # if bool(input_arr_debug.ndim > 1):\n",
    "                #     print(f\"{input_ls = }\")\n",
    "                #     print(f\"{df.values.tolist()[idxs_ls[min_idx]] = }\")\n",
    "            except Exception as err:\n",
    "                print(f\"Inside except block... {err}\")\n",
    "  \n",
    "        # print(f\"{input_ls = }\")\n",
    "        input_arr = np.array(input_ls)\n",
    "        # print(f\"{input_arr = }\")\n",
    "        min_idx = np.argmin(input_arr, axis=0)[d]\n",
    "        # print(f\"{min_idx = }\")\n",
    "        output_ls.append(input_ls[min_idx])\n",
    "        # print(f\"{output_ls = }\")\n",
    "        input_ls.pop(min_idx)\n",
    "        idxs_ls[min_idx] += 1\n",
    "        # print(f\"{idxs_ls = }\")\n",
    "\n",
    "        #Writing output\n",
    "        if len(output_ls) >= output_len_ls[output_len_idx]:\n",
    "            # print(f\"{output_ls = }\")\n",
    "            # print(f\"{output_len_idx = }\")\n",
    "            # print(f\"{output_len_ls[output_len_idx] = }\")\n",
    "            sorted_chunk_df = pd.DataFrame(output_ls, columns=df_columns)\n",
    "            sorted_chunk_df.to_pickle(f\"{file_path}{iteration_num}{output_len_idx}.pkl\")\n",
    "            output_ls = []\n",
    "            output_len_idx += 1\n",
    "        \n",
    "        if idxs_ls[min_idx] > (index_ls[min_idx] -1):\n",
    "            # print(f\"Inside greater than condition...\")\n",
    "            idxs_ls.pop(min_idx)\n",
    "            sorted_chunks_path_cpy.pop(min_idx)\n",
    "            index_ls.pop(min_idx)\n",
    "            if len(input_ls) == 0:\n",
    "                break \n",
    "            try:\n",
    "                if min_idx > len(input_ls) - 1:\n",
    "                    min_idx -= 1\n",
    "                    input_ls.pop(min_idx)\n",
    "                else:\n",
    "                    input_ls.pop(min_idx)\n",
    "            except Exception as err:\n",
    "                print(f\"err: {err}\")\n",
    "                print(f\"{input_ls = }\")\n",
    "                print(f\"{min_idx = }\")\n",
    "                print(f\"{sorted_chunks_path_cpy = }\")\n",
    "                print(f\"{index_ls = }\")\n",
    "                \n",
    "    #Remove sorted_chunk_paths\n",
    "    for sorted_chunk in sorted_chunk_paths:\n",
    "        os.remove(sorted_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c989479-8cef-4ced-9c96-b0f3b7d514ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUC implementation\n",
    "# from external_merge_sort import external_merge_sort_implementation\n",
    "class buc_external:\n",
    "    '''\n",
    "    Class for implementing BUC\n",
    "    '''\n",
    "    def __init__(self, df, column_enc_dicts_ls, minsup):\n",
    "        self.numDims = df.shape[1]\n",
    "        self.cardinality = []\n",
    "        self.minsup = minsup\n",
    "        self.output_df = None\n",
    "        self.datacounts = [[]] * df.shape[1]\n",
    "        self.attribute_ls = [\"*\"] * df.shape[1]\n",
    "        self.debug_counter = 0\n",
    "        self.output_dict = {}\n",
    "        self.column_enc_dicts_ls = column_enc_dicts_ls\n",
    "        self.file_path = './dfs/iter_run_'\n",
    "\n",
    "    def counting_sort(self, array_a, df_idx_ls):\n",
    "      '''\n",
    "      Inputs \n",
    "      array_a: List to be sorted\n",
    "      df_idx_ls: Index list corresponding to the array_a. For example: DataFrame indices corresponding to array_a.\n",
    "      Output\n",
    "      idx_ls: Order in which df_idx_ls should be arranged so that array_a is in the sorted order.\n",
    "      '''\n",
    "      array_c = [0]*(max(array_a) + 1)\n",
    "      idx_ls = [-1] * (len(array_a))\n",
    "\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{array_c = }\")\n",
    "      for i in range(0, len(array_a)):\n",
    "        array_c[array_a[i]] += 1\n",
    "\n",
    "      for i in range(0, len(array_c) - 1):\n",
    "        array_c[i+1] = array_c[i] + array_c[i+1]\n",
    "\n",
    "      for i in range(len(array_a) - 1, -1, -1):\n",
    "        array_c[array_a[i]] = array_c[array_a[i]] - 1\n",
    "        idx = array_c[array_a[i]]\n",
    "        idx_ls[idx] = df_idx_ls[i]\n",
    "\n",
    "      # idx_ls = [i + min_idx for i in idx_ls]\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{idx_ls = }\")\n",
    "      return idx_ls\n",
    "\n",
    "    def partition(self, iteration_num, num_splits, index_dict, d):\n",
    "        chunk_paths_ls = []\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                chunk_paths_ls.append(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                \n",
    "        # print(f\"chunk_paths_ls: {chunk_paths_ls}\")\n",
    "        # print(f\"BEFORE SORTING!!!\")\n",
    "        # for i_iter in range(0, num_splits):\n",
    "        #     print(f\"{i_iter = }\")\n",
    "        #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "        #         df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "        #         print(f\"{df = }\")\n",
    "                \n",
    "        external_merge_sort_implementation(chunk_paths_ls, d, iteration_num, index_dict, self.file_path)\n",
    "        \n",
    "        # print(f\"AFTER SORTING!!!\")\n",
    "        #Checking \n",
    "        input_df = pd.DataFrame()\n",
    "        for i_iter in range(0, num_splits):\n",
    "            # print(f\"{i_iter = }\")\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                # print(f\"{df = }\")\n",
    "                input_df = pd.concat([input_df, df])\n",
    "        \n",
    "        #Populating self.datacounts\n",
    "        temp_counter_dict = {}\n",
    "        for attribute in input_df.iloc[:,d].tolist():\n",
    "            temp_counter_dict[attribute] = temp_counter_dict.get(attribute, 0) + 1\n",
    "        self.datacounts[d] = [*temp_counter_dict.values()]\n",
    "        return None\n",
    "                \n",
    "    # def partition(self, iteration_num, num_splits, d, bigc):\n",
    "    #     '''\n",
    "    #     Implements partitioning logic i.e sorts the input dataframe and populates self.datacounts\n",
    "    #     Inputs:\n",
    "    #     input_df: Input DataFrame\n",
    "    #     d: column number based on which sorting is performed\n",
    "    #     Output:\n",
    "    #     input_df: DataFrame which is sorted according to the specified column\n",
    "    #     '''\n",
    "    #     #Read the entire dataframe and concatenate everything\n",
    "    #     #################################################ONLY FOR TESTING: REPLACE THIS WITH EXTERNAL MERGE SORT########################################\n",
    "    #     # print(f\"Inside partition\")\n",
    "    #     # print(f\"{iteration_num = }\")\n",
    "    #     # print(f\"{num_splits = }\")\n",
    "    #     ################################################################################################################################################\n",
    "    #     df = pd.DataFrame()\n",
    "    #     for i_iter in range(0, num_splits):\n",
    "    #         if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "    #             temp_df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "    #             df = pd.concat([df, temp_df])\n",
    "            \n",
    "    #     input_df = df\n",
    "    #     #Sorting the dataframe\n",
    "    #     temp_counter_dict = {}\n",
    "    #     sorted_idx = self.counting_sort(input_df.iloc[:,d].tolist(), input_df.index.tolist())\n",
    "    #     input_df = input_df.reindex(sorted_idx)\n",
    "    #     #Populating self.datacounts\n",
    "    #     for attribute in input_df.iloc[:,d].tolist():\n",
    "    #         temp_counter_dict[attribute] = temp_counter_dict.get(attribute, 0) + 1\n",
    "    #     self.datacounts[d] = [*temp_counter_dict.values()]\n",
    "        \n",
    "    #     #Write the sorted files back to the disk\n",
    "    #     # split_df = np.array_split(input_df, num_splits)\n",
    "    #     with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"rb\") as fp:\n",
    "    #         index_dict_t = pickle.load(fp)\n",
    "\n",
    "    #     # print(f\"Inside partition\")\n",
    "    #     # print(f\"{index_dict_t = }\")\n",
    "    #     # print(f\"{input_df = }\")\n",
    "    #     for df_name, df_idxs in index_dict_t.items():\n",
    "    #         split_df = pd.DataFrame(input_df.iloc[df_idxs,:])\n",
    "    #         split_df.to_pickle(f\"{self.file_path}{iteration_num}{df_name}.pkl\")\n",
    "    #     return None        \n",
    "        \n",
    "    def compute_aggregate(self, iteration_num, num_splits):\n",
    "        count = 0\n",
    "        for i_iter in range(0,num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                count += df.shape[0]\n",
    "        return count\n",
    "\n",
    "    def find_bigc(self, iteration_num, num_splits, d): \n",
    "        '''\n",
    "        Bigc refers to the cardinality of the dth attribute in the dataframe\n",
    "        '''\n",
    "        computed_values = []\n",
    "        bigc = 0\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                for attribute_name in df.iloc[:,d].unique().tolist():\n",
    "                    if attribute_name not in computed_values:\n",
    "                        computed_values.append(attribute_name)\n",
    "                        bigc += 1\n",
    "        return bigc\n",
    "\n",
    "    def split_input(self, slice_range, iteration_num, num_splits):\n",
    "        #Delete previous files of current iteration\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                os.remove(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                # print(f\"Inside remove function...\")\n",
    "                            \n",
    "        # print(f\"{iteration_num = }, {slice_range =}\")\n",
    "        index_dict_t = {} #Stores the indices that are present in each dictionary\n",
    "        # print(f\"{self.file_path}{iteration_num-1}0.pkl\")\n",
    "        if not os.path.exists(f\"{self.file_path}{iteration_num-1}0.pkl\"):\n",
    "            #Dimension = 0\n",
    "            input_df = transformed_df\n",
    "            split_df = np.array_split(input_df, num_splits)\n",
    "            start_idx = 0\n",
    "            for i_iter, df in enumerate(split_df):\n",
    "                # print(f\"DF after splitting: {df}\")\n",
    "                df.to_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                index_dict_t[i_iter] = [*range(start_idx, start_idx + df.shape[0])]\n",
    "                start_idx += df.shape[0]   \n",
    "            # print(f\"{index_dict_t = }\")\n",
    "            with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"wb\") as fp:\n",
    "                pickle.dump(index_dict_t, fp)\n",
    "        else:  \n",
    "            if (slice_range[1] - slice_range[0]) < num_splits:\n",
    "                df_lengths_t = [slice_range[1] - slice_range[0]]\n",
    "                df_lengths_t.extend([0]*(num_splits-1))\n",
    "            else:\n",
    "                df_lengths_t = [math.floor((slice_range[1] - slice_range[0])/num_splits)]*num_splits\n",
    "                df_lengths_t[-1] += (slice_range[1] - slice_range[0])%num_splits\n",
    "            # print(f\"{df_lengths_t = }\")\n",
    "            df_ranges_t_ls = []\n",
    "            start_idx = slice_range[0]\n",
    "            for df_length in df_lengths_t:\n",
    "                if df_length != 0:\n",
    "                    df_ranges_t_ls.append([*range(start_idx,start_idx + df_length)])\n",
    "                    start_idx += df_length\n",
    "            # print(f\"{df_ranges_t_ls = }\")\n",
    "            del start_idx \n",
    "            \n",
    "            with open(f\"{self.file_path}_dict_{iteration_num-1}.pkl\", \"rb\") as fp:\n",
    "                index_dict_tminus = pickle.load(fp)\n",
    "\n",
    "            # print(f\"{index_dict_tminus = }\")\n",
    "            start_dict_idx = 0\n",
    "            index_dict_t = {}\n",
    "            # print(f\"{index_dict_tminus = }\")\n",
    "            # print(f\"{df_ranges_t_ls = }\")\n",
    "            for i_iter, df_range_t in enumerate(df_ranges_t_ls):\n",
    "                start_df_idx = 0\n",
    "                # print(f\"{df_range_t = }\")\n",
    "                df = pd.DataFrame()\n",
    "                for df_tminus_name, df_tminus_range in index_dict_tminus.items():\n",
    "                    # print(f\"{df_tminus_range = }\")\n",
    "                    # print(f\"{start_df_idx = }\")\n",
    "                    common_elements = [i for i in df_range_t for j in df_tminus_range if i == j]\n",
    "                    common_elements = [i-start_df_idx for i in common_elements]\n",
    "                    # print(f\"{df_tminus_name = }\")\n",
    "                    # print(f\"{common_elements = }\")\n",
    "                    if len(common_elements) > 0:\n",
    "                        temp_df = pd.read_pickle(f\"{self.file_path}{iteration_num-1}{df_tminus_name}.pkl\")\n",
    "                        df = pd.concat([df, temp_df.iloc[common_elements,:]])\n",
    "                    start_df_idx += len(df_tminus_range)\n",
    "                df.to_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                index_dict_t[i_iter] = [*range(start_dict_idx, start_dict_idx + df.shape[0])]\n",
    "                start_dict_idx += df.shape[0]\n",
    "                # print(f\"{index_dict_t = }\")\n",
    "                with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"wb\") as fp:\n",
    "                    pickle.dump(index_dict_t, fp)\n",
    "                # print(f\"{iteration_num = }, {i_iter = }\")\n",
    "                # print(f\"{df.info =}\")                \n",
    "        return index_dict_t\n",
    "\n",
    "    def populate_attribute_ls(self, k, d, iteration_num):\n",
    "        with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"rb\") as fp:\n",
    "            index_dict_t = pickle.load(fp)\n",
    "\n",
    "        k_idx = k\n",
    "        for df_name, df_idxs in index_dict_t.items():\n",
    "            if k in df_idxs:\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{df_name}.pkl\")\n",
    "                self.attribute_ls[d] = self.column_enc_dicts_ls[d][df.iloc[k_idx,d]]\n",
    "                return None\n",
    "            k_idx -= len(df_idxs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def buc_implementation(self, slice_range, dim, iteration_num, num_splits):\n",
    "        '''\n",
    "        Function to implement BUC as indicated in the original paper. \n",
    "        Populates self.output_dict which is the output dictionary.\n",
    "        NOTE:All the variable names are exactly as indicated in the original paper.\n",
    "        Input\n",
    "        input: Input DataFrame\n",
    "        dim: Starting column for performing aggregation\n",
    "        '''\n",
    "        # print()\n",
    "        self.debug_counter += 1\n",
    "        if self.debug_counter % 10 == 0:\n",
    "            print(f\"{self.debug_counter = }\")\n",
    "        index_dict = self.split_input(slice_range, iteration_num, num_splits)\n",
    "       \n",
    "        # if self.debug_counter == 10:\n",
    "            # return {}\n",
    "        # print(f\"{self.output_dict}, {self.attribute_ls}\")\n",
    "        # if tuple(self.attribute_ls) in [*self.output_dict.keys()]:\n",
    "            # print(f\"Error!!\")\n",
    "        # print(f\"Before aggregate computation\")\n",
    "        # for i_iter in range(0, num_splits):\n",
    "        #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "        #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "        #         print(f\"{df_debug.info}\")\n",
    "        aggregate = self.compute_aggregate(iteration_num, num_splits)\n",
    "        # print(f\"AGGREGATE: {aggregate}\")\n",
    "        # print(f\"{self.attribute_ls = }\")\n",
    "        self.output_dict[tuple(self.attribute_ls)] = aggregate\n",
    "        # if self.debug_counter == 10:\n",
    "            # return \n",
    "        # print(f\"{dim = }\")\n",
    "        for d in range(dim, self.numDims,1):\n",
    "            # bigc = input.iloc[:,d].nunique()\n",
    "            bigc = self.find_bigc(iteration_num, num_splits, d)\n",
    "            # print(f\"{d = }\")\n",
    "            # print(f\"{bigc = }\")\n",
    "            # print(f\"{d= }, {bigc=}\")\n",
    "            # print(f\"Input before partitioning: {input}\")\n",
    "            # print(f\"Before partition\")\n",
    "            # for i_iter in range(0, num_splits):\n",
    "            #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "            #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "            #         print(f\"{df_debug.info}\")\n",
    "            self.partition(iteration_num, num_splits, index_dict, d)\n",
    "            # print(f\"{iteration_num = }\")\n",
    "            # print(f\"After partition\")\n",
    "            # for i_iter in range(0, num_splits):\n",
    "            #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "            #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "            #         print(f\"{df_debug.info}\")\n",
    "            # return {}\n",
    "            # print(f\"Input after partitioning on {d}: {input}\")\n",
    "            # print(f\"{self.datacounts = }\")\n",
    "            k = 0\n",
    "            for i in range(0, bigc, 1):\n",
    "                # print(f\"{iteration_num = }, {i = }, {bigc = }\")\n",
    "                # print(f\"################Inside i loop######################\")\n",
    "                # print(f\"{input = }\")\n",
    "                # print(f\"{d = }, {i = }\")\n",
    "                # print(f\"{self.datacounts = }\")\n",
    "                smallc = self.datacounts[d][i]\n",
    "                # print(f\"{smallc = }\")\n",
    "                if smallc >= self.minsup:\n",
    "                    # print(f\"**********************Inside if condition***********************\")\n",
    "                    # print(f\"k:{k}, d:{d}\")\n",
    "                    # print(f\"Attribute: {input.iloc[k,d]}\")\n",
    "                    # print(f\"{transformed_dicts[d] = }\")\n",
    "                    # input = transformed_df\n",
    "                    # input = transformed_df\n",
    "                    # self.attribute_ls[d] = self.column_enc_dicts_ls[d][input.iloc[k,d]]\n",
    "                    # del input\n",
    "                    # print(f\"{self.attribute_ls = }\")\n",
    "                    # print(f\"smallc: {smallc}\")\n",
    "                    # self.buc_implementation(input.iloc[k:k+smallc,:], dim=d+1, iteration_num=iteration_num+1)\n",
    "                    self.populate_attribute_ls(k, d, iteration_num)\n",
    "                    self.buc_implementation(slice_range = [k,k+smallc], dim=d+1, iteration_num=iteration_num+1, num_splits=num_splits)\n",
    "                    # if self.debug_counter == 10:\n",
    "                        # return {}\n",
    "                    # print(f\"d inside if condition: {d}\")\n",
    "                    # print(f\"******************************************************************\")\n",
    "                k += smallc\n",
    "            # print(f\"#################################################################\")\n",
    "            # print(f\"ALL:\")\n",
    "            # print(f\"k:{k}, d:{d}\")\n",
    "            self.attribute_ls[d] = \"*\"\n",
    "            # print(f\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e01c752e-5fdc-467b-9ce5-85fc6976669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names = ['country', 'year', 'sex', 'age', 'generation', 'suicides_range', 'population_range', 'gdp_per_year_income_range']\n"
     ]
    }
   ],
   "source": [
    "#Parameter\n",
    "minsup = 100\n",
    "input_df = data\n",
    "num_splits = 10\n",
    "# print(f\"input_df: {input_df}\")\n",
    "preprocess_obj = preprocess_df()\n",
    "transformed_df, column_enc_dicts_ls = preprocess_obj.encode_attributes(input_df, [*range(0,input_df.shape[1])]) #NOTE: This should be modified as required\n",
    "# print(f\"transformed_df: {transformed_df}\")\n",
    "# print(f\"column_enc_dicts_ls: {column_enc_dicts_ls}\")\n",
    "buc_obj = buc(transformed_df, column_enc_dicts_ls, minsup)\n",
    "buc_obj.buc_implementation(transformed_df, 0)\n",
    "# buc_obj = buc_external(transformed_df, column_enc_dicts_ls, minsup)\n",
    "# buc_obj.buc_implementation([0,transformed_df.shape[0]], 0, 0, num_splits)\n",
    "output_dict = buc_obj.output_dict\n",
    "# print(f\"{output_dict = }\")\n",
    "# output_df = pd.DataFrame(columns=input_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "95588aa2-3a4f-4185-8ab3-e3f5d133673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>generation</th>\n",
       "      <th>suicides_range</th>\n",
       "      <th>population_range</th>\n",
       "      <th>gdp_per_year_income_range</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>27820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>male</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>male</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>low_suicides_range</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>male</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>medium_population_range</td>\n",
       "      <td>*</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>high_population_range</td>\n",
       "      <td>medium_income_range</td>\n",
       "      <td>2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>high_population_range</td>\n",
       "      <td>high_income_range</td>\n",
       "      <td>4727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>low_income_range</td>\n",
       "      <td>6958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>medium_income_range</td>\n",
       "      <td>13910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>high_income_range</td>\n",
       "      <td>6952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6607 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country year   sex age generation      suicides_range  \\\n",
       "0           *    *     *   *          *                   *   \n",
       "1     Albania    *     *   *          *                   *   \n",
       "2     Albania    *  male   *          *                   *   \n",
       "3     Albania    *  male   *          *  low_suicides_range   \n",
       "4     Albania    *  male   *          *                   *   \n",
       "...       ...  ...   ...  ..        ...                 ...   \n",
       "6602        *    *     *   *          *                   *   \n",
       "6603        *    *     *   *          *                   *   \n",
       "6604        *    *     *   *          *                   *   \n",
       "6605        *    *     *   *          *                   *   \n",
       "6606        *    *     *   *          *                   *   \n",
       "\n",
       "             population_range gdp_per_year_income_range  count  \n",
       "0                           *                         *  27820  \n",
       "1                           *                         *    264  \n",
       "2                           *                         *    132  \n",
       "3                           *                         *    119  \n",
       "4     medium_population_range                         *    110  \n",
       "...                       ...                       ...    ...  \n",
       "6602    high_population_range       medium_income_range   2219  \n",
       "6603    high_population_range         high_income_range   4727  \n",
       "6604                        *          low_income_range   6958  \n",
       "6605                        *       medium_income_range  13910  \n",
       "6606                        *         high_income_range   6952  \n",
       "\n",
       "[6607 rows x 9 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict_transformed = {}\n",
    "columns_ls = input_df.columns.tolist()\n",
    "for column in columns_ls:\n",
    "    output_dict_transformed[column] = []\n",
    "    output_dict_transformed['count'] = []\n",
    "for tuple_key, value in output_dict.items():\n",
    "    output_dict_transformed['count'].append(value)\n",
    "    for tuple_key_iter in range(0,len(tuple_key)):\n",
    "        output_dict_transformed[columns_ls[tuple_key_iter]].append(tuple_key[tuple_key_iter])\n",
    "# print(f\"{output_dict = }\")\n",
    "# print(f\"{output_dict_transformed = }\")\n",
    "output_df = pd.DataFrame.from_dict(output_dict_transformed)\n",
    "# columns_order = ['Country', 'Year', 'Sex', 'count']\n",
    "columns_order = ['country', 'year', 'sex', 'age', 'generation', 'suicides_range', 'population_range', 'gdp_per_year_income_range', 'count']\n",
    "output_df = output_df.reindex(columns = columns_order)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fad42ef4-6947-4901-b96a-ba5226e63d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buc_external_ten_df = output_df\n",
    "buc_external_ten_df.equals(output_df)\n",
    "# print(buc_internal_df.equals(output_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
