{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d411c0-5272-450b-9f1c-d9a080e12d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "709c001e-daf2-422d-a236-6ea7e45682b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (27820, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex          age  suicides_no  population  \\\n",
       "0  Albania  1987    male  15-24 years           21      312900   \n",
       "1  Albania  1987    male  35-54 years           16      308000   \n",
       "2  Albania  1987  female  15-24 years           14      289700   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year   gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987           NaN          2156624900   \n",
       "1               5.19  Albania1987           NaN          2156624900   \n",
       "2               4.83  Albania1987           NaN          2156624900   \n",
       "\n",
       "   gdp_per_capita ($)    generation  \n",
       "0                 796  Generation X  \n",
       "1                 796        Silent  \n",
       "2                 796  Generation X  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(f'./data/master.xlsx') # Load the Excel dataset\n",
    "print('Shape of the dataset:', data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b809220-b77d-44ea-9c25-ca77bea8e888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1dc438-898f-4224-b56d-c504f2575bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of    Country  Year Sex\n",
      "0  Albania  2009   m\n",
      "1  Albania  2009   m\n",
      "2  Albania  2010   m\n",
      "3  Albania  2011   m\n",
      "4  Albania  2011   m\n",
      "5  Albania  2012   f\n",
      "6   Russia  2010   f\n",
      "7   Russia  2012   f\n",
      "8    India  2009   f\n",
      "9    India  2010   f>\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "##DataFrame for unit testing\n",
    "country_name_ls = ['Albania'] *6 + ['Russia']*2 + ['India']*2\n",
    "year_ls = ['2009', '2009','2010', '2011', '2011', '2012', '2010', '2012', '2009', '2010']\n",
    "# sex_ls = ['m']*4 + ['f']*2 + ['m'] + ['f']*3\n",
    "sex_ls = ['m']*5 + ['f']*5\n",
    "test_df = pd.DataFrame()\n",
    "test_df['Country'] = country_name_ls\n",
    "test_df['Year'] = year_ls\n",
    "test_df['Sex'] = sex_ls\n",
    "print(test_df.info)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef756190-8722-4f77-8687-871402720c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_df:\n",
    "  '''\n",
    "  Class to preprocess DataFrame\n",
    "  '''\n",
    "  def encode_attributes(self, input_df, column_indices):\n",
    "    transformed_dicts_ls = []\n",
    "    transformed_df = input_df.copy(deep = True)\n",
    "    column_names = transformed_df.columns.tolist()\n",
    "    # print(f\"{column_names = }\")\n",
    "    for col_iter in column_indices:\n",
    "      temp_dict = {}\n",
    "      temp_key = 0\n",
    "      temp_ls = []\n",
    "      column_name = column_names[col_iter]\n",
    "      for col in transformed_df.iloc[:,col_iter].tolist():\n",
    "        if col not in [*temp_dict.keys()]:\n",
    "          temp_dict[col] = temp_key\n",
    "          temp_key += 1\n",
    "        temp_ls.append(temp_dict[col])\n",
    "      dict_inv = {v:k for k,v in temp_dict.items()}\n",
    "      transformed_dicts_ls.append(dict_inv)\n",
    "      transformed_df[column_name] = temp_ls\n",
    "    return transformed_df, transformed_dicts_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d632684-f8fa-48f0-bd9c-82c5534a2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUC implementation\n",
    "class buc_external:\n",
    "    '''\n",
    "    Class for implementing BUC\n",
    "    '''\n",
    "    def __init__(self, df, column_enc_dicts_ls, minsup):\n",
    "        self.numDims = df.shape[1]\n",
    "        self.cardinality = []\n",
    "        self.minsup = minsup\n",
    "        self.output_df = None\n",
    "        self.datacounts = [[]] * df.shape[1]\n",
    "        self.attribute_ls = [\"*\"] * df.shape[1]\n",
    "        self.debug_counter = 0\n",
    "        self.output_dict = {}\n",
    "        self.column_enc_dicts_ls = column_enc_dicts_ls\n",
    "        self.file_path = './dfs/iter_run_'\n",
    "\n",
    "    def counting_sort(self, array_a, df_idx_ls):\n",
    "      '''\n",
    "      Inputs \n",
    "      array_a: List to be sorted\n",
    "      df_idx_ls: Index list corresponding to the array_a. For example: DataFrame indices corresponding to array_a.\n",
    "      Output\n",
    "      idx_ls: Order in which df_idx_ls should be arranged so that array_a is in the sorted order.\n",
    "      '''\n",
    "      array_c = [0]*(max(array_a) + 1)\n",
    "      idx_ls = [-1] * (len(array_a))\n",
    "\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{array_c = }\")\n",
    "      for i in range(0, len(array_a)):\n",
    "        array_c[array_a[i]] += 1\n",
    "\n",
    "      for i in range(0, len(array_c) - 1):\n",
    "        array_c[i+1] = array_c[i] + array_c[i+1]\n",
    "\n",
    "      for i in range(len(array_a) - 1, -1, -1):\n",
    "        array_c[array_a[i]] = array_c[array_a[i]] - 1\n",
    "        idx = array_c[array_a[i]]\n",
    "        idx_ls[idx] = df_idx_ls[i]\n",
    "\n",
    "      # idx_ls = [i + min_idx for i in idx_ls]\n",
    "      # print(f\"{array_a = }\")\n",
    "      # print(f\"{idx_ls = }\")\n",
    "      return idx_ls\n",
    "\n",
    "\n",
    "    def partition(self, iteration_num, num_splits, d, bigc):\n",
    "        '''\n",
    "        Implements partitioning logic i.e sorts the input dataframe and populates self.datacounts\n",
    "        Inputs:\n",
    "        input_df: Input DataFrame\n",
    "        d: column number based on which sorting is performed\n",
    "        Output:\n",
    "        input_df: DataFrame which is sorted according to the specified column\n",
    "        '''\n",
    "        #Read the entire dataframe and concatenate everything\n",
    "        #################################################ONLY FOR TESTING: REPLACE THIS WITH EXTERNAL MERGE SORT########################################\n",
    "        # print(f\"Inside partition\")\n",
    "        # print(f\"{iteration_num = }\")\n",
    "        # print(f\"{num_splits = }\")\n",
    "        ################################################################################################################################################\n",
    "        df = pd.DataFrame()\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                temp_df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "        input_df = df\n",
    "        #Sorting the dataframe\n",
    "        temp_counter_dict = {}\n",
    "        sorted_idx = self.counting_sort(input_df.iloc[:,d].tolist(), input_df.index.tolist())\n",
    "        input_df = input_df.reindex(sorted_idx)\n",
    "        #Populating self.datacounts\n",
    "        for attribute in input_df.iloc[:,d].tolist():\n",
    "            temp_counter_dict[attribute] = temp_counter_dict.get(attribute, 0) + 1\n",
    "        self.datacounts[d] = [*temp_counter_dict.values()]\n",
    "        \n",
    "        #Write the sorted files back to the disk\n",
    "        # split_df = np.array_split(input_df, num_splits)\n",
    "        with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"rb\") as fp:\n",
    "            index_dict_t = pickle.load(fp)\n",
    "\n",
    "        # print(f\"Inside partition\")\n",
    "        # print(f\"{index_dict_t = }\")\n",
    "        # print(f\"{input_df = }\")\n",
    "        for df_name, df_idxs in index_dict_t.items():\n",
    "            split_df = pd.DataFrame(input_df.iloc[df_idxs,:])\n",
    "            split_df.to_pickle(f\"{self.file_path}{iteration_num}{df_name}.pkl\")\n",
    "        return None        \n",
    "        \n",
    "    def compute_aggregate(self, iteration_num, num_splits):\n",
    "        count = 0\n",
    "        for i_iter in range(0,num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                count += df.shape[0]\n",
    "        return count\n",
    "\n",
    "    def find_bigc(self, iteration_num, num_splits, d): \n",
    "        '''\n",
    "        Bigc refers to the cardinality of the dth attribute in the dataframe\n",
    "        '''\n",
    "        computed_values = []\n",
    "        bigc = 0\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                for attribute_name in df.iloc[:,d].unique().tolist():\n",
    "                    if attribute_name not in computed_values:\n",
    "                        computed_values.append(attribute_name)\n",
    "                        bigc += 1\n",
    "        return bigc\n",
    "\n",
    "    def split_input(self, slice_range, iteration_num):\n",
    "        num_splits = 2  \n",
    "        #Delete previous files of current iteration\n",
    "        for i_iter in range(0, num_splits):\n",
    "            if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "                os.remove(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                # print(f\"Inside remove function...\")\n",
    "                            \n",
    "        # print(f\"{iteration_num = }, {slice_range =}\")\n",
    "        index_dict_t = {} #Stores the indices that are present in each dictionary\n",
    "        # print(f\"{self.file_path}{iteration_num-1}0.pkl\")\n",
    "        if not os.path.exists(f\"{self.file_path}{iteration_num-1}0.pkl\"):\n",
    "            #Dimension = 0\n",
    "            input_df = transformed_df\n",
    "            split_df = np.array_split(input_df, num_splits)\n",
    "            start_idx = 0\n",
    "            for i_iter, df in enumerate(split_df):\n",
    "                # print(f\"DF after splitting: {df}\")\n",
    "                df.to_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                index_dict_t[i_iter] = [*range(start_idx, start_idx + df.shape[0])]\n",
    "                start_idx += df.shape[0]   \n",
    "            # print(f\"{index_dict_t = }\")\n",
    "            with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"wb\") as fp:\n",
    "                pickle.dump(index_dict_t, fp)\n",
    "        else:  \n",
    "            if (slice_range[1] - slice_range[0]) < num_splits:\n",
    "                df_lengths_t = [slice_range[1] - slice_range[0]]\n",
    "                df_lengths_t.extend([0]*(num_splits-1))\n",
    "            else:\n",
    "                df_lengths_t = [math.floor((slice_range[1] - slice_range[0])/num_splits)]*num_splits\n",
    "                df_lengths_t[-1] += (slice_range[1] - slice_range[0])%num_splits\n",
    "            # print(f\"{df_lengths_t = }\")\n",
    "            df_ranges_t_ls = []\n",
    "            start_idx = slice_range[0]\n",
    "            for df_length in df_lengths_t:\n",
    "                if df_length != 0:\n",
    "                    df_ranges_t_ls.append([*range(start_idx,start_idx + df_length)])\n",
    "                    start_idx += df_length\n",
    "            # print(f\"{df_ranges_t_ls = }\")\n",
    "            del start_idx \n",
    "            \n",
    "            with open(f\"{self.file_path}_dict_{iteration_num-1}.pkl\", \"rb\") as fp:\n",
    "                index_dict_tminus = pickle.load(fp)\n",
    "\n",
    "            # print(f\"{index_dict_tminus = }\")\n",
    "            start_dict_idx = 0\n",
    "            index_dict_t = {}\n",
    "            # print(f\"{index_dict_tminus = }\")\n",
    "            # print(f\"{df_ranges_t_ls = }\")\n",
    "            for i_iter, df_range_t in enumerate(df_ranges_t_ls):\n",
    "                start_df_idx = 0\n",
    "                # print(f\"{df_range_t = }\")\n",
    "                df = pd.DataFrame()\n",
    "                for df_tminus_name, df_tminus_range in index_dict_tminus.items():\n",
    "                    # print(f\"{df_tminus_range = }\")\n",
    "                    # print(f\"{start_df_idx = }\")\n",
    "                    common_elements = [i for i in df_range_t for j in df_tminus_range if i == j]\n",
    "                    common_elements = [i-start_df_idx for i in common_elements]\n",
    "                    # print(f\"{df_tminus_name = }\")\n",
    "                    # print(f\"{common_elements = }\")\n",
    "                    if len(common_elements) > 0:\n",
    "                        temp_df = pd.read_pickle(f\"{self.file_path}{iteration_num-1}{df_tminus_name}.pkl\")\n",
    "                        df = pd.concat([df, temp_df.iloc[common_elements,:]])\n",
    "                    start_df_idx += len(df_tminus_range)\n",
    "                df.to_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "                index_dict_t[i_iter] = [*range(start_dict_idx, start_dict_idx + df.shape[0])]\n",
    "                start_dict_idx += df.shape[0]\n",
    "                # print(f\"{index_dict_t = }\")\n",
    "                with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"wb\") as fp:\n",
    "                    pickle.dump(index_dict_t, fp)\n",
    "                # print(f\"{iteration_num = }, {i_iter = }\")\n",
    "                # print(f\"{df.info =}\")                \n",
    "        return num_splits\n",
    "\n",
    "    def populate_attribute_ls(self, k, d, iteration_num):\n",
    "        with open(f\"{self.file_path}_dict_{iteration_num}.pkl\", \"rb\") as fp:\n",
    "            index_dict_t = pickle.load(fp)\n",
    "\n",
    "        k_idx = k\n",
    "        for df_name, df_idxs in index_dict_t.items():\n",
    "            if k in df_idxs:\n",
    "                df = pd.read_pickle(f\"{self.file_path}{iteration_num}{df_name}.pkl\")\n",
    "                self.attribute_ls[d] = self.column_enc_dicts_ls[d][df.iloc[k_idx,d]]\n",
    "                return None\n",
    "            k_idx -= len(df_idxs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def buc_implementation(self, slice_range, dim, iteration_num):\n",
    "        '''\n",
    "        Function to implement BUC as indicated in the original paper. \n",
    "        Populates self.output_dict which is the output dictionary.\n",
    "        NOTE:All the variable names are exactly as indicated in the original paper.\n",
    "        Input\n",
    "        input: Input DataFrame\n",
    "        dim: Starting column for performing aggregation\n",
    "        '''\n",
    "        # print()\n",
    "        self.debug_counter += 1\n",
    "        num_splits = self.split_input(slice_range, iteration_num)\n",
    "       \n",
    "        # if self.debug_counter == 10:\n",
    "            # return {}\n",
    "        # print(f\"{self.output_dict}, {self.attribute_ls}\")\n",
    "        # if tuple(self.attribute_ls) in [*self.output_dict.keys()]:\n",
    "            # print(f\"Error!!\")\n",
    "        # print(f\"Before aggregate computation\")\n",
    "        # for i_iter in range(0, num_splits):\n",
    "        #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "        #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "        #         print(f\"{df_debug.info}\")\n",
    "        aggregate = self.compute_aggregate(iteration_num, num_splits)\n",
    "        # print(f\"AGGREGATE: {aggregate}\")\n",
    "        # print(f\"{self.attribute_ls = }\")\n",
    "        self.output_dict[tuple(self.attribute_ls)] = aggregate\n",
    "        # if self.debug_counter == 10:\n",
    "            # return \n",
    "        # print(f\"{dim = }\")\n",
    "        for d in range(dim, self.numDims,1):\n",
    "            # bigc = input.iloc[:,d].nunique()\n",
    "            bigc = self.find_bigc(iteration_num, num_splits, d)\n",
    "            # print(f\"{d = }\")\n",
    "            # print(f\"{bigc = }\")\n",
    "            # print(f\"{d= }, {bigc=}\")\n",
    "            # print(f\"Input before partitioning: {input}\")\n",
    "            # print(f\"Before partition\")\n",
    "            # for i_iter in range(0, num_splits):\n",
    "            #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "            #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "            #         print(f\"{df_debug.info}\")\n",
    "            self.partition(iteration_num, num_splits, d, bigc)\n",
    "            # print(f\"{iteration_num = }\")\n",
    "            # print(f\"After partition\")\n",
    "            # for i_iter in range(0, num_splits):\n",
    "            #     if os.path.exists(f\"{self.file_path}{iteration_num}{i_iter}.pkl\"):\n",
    "            #         df_debug = pd.read_pickle(f\"{self.file_path}{iteration_num}{i_iter}.pkl\")\n",
    "            #         print(f\"{df_debug.info}\")\n",
    "            # return {}\n",
    "            # print(f\"Input after partitioning on {d}: {input}\")\n",
    "            # print(f\"{self.datacounts = }\")\n",
    "            k = 0\n",
    "            for i in range(0, bigc, 1):\n",
    "                # print(f\"{iteration_num = }, {i = }, {bigc = }\")\n",
    "                # print(f\"################Inside i loop######################\")\n",
    "                # print(f\"{input = }\")\n",
    "                # print(f\"{d = }, {i = }\")\n",
    "                # print(f\"{self.datacounts = }\")\n",
    "                smallc = self.datacounts[d][i]\n",
    "                # print(f\"{smallc = }\")\n",
    "                if smallc >= self.minsup:\n",
    "                    # print(f\"**********************Inside if condition***********************\")\n",
    "                    # print(f\"k:{k}, d:{d}\")\n",
    "                    # print(f\"Attribute: {input.iloc[k,d]}\")\n",
    "                    # print(f\"{transformed_dicts[d] = }\")\n",
    "                    # input = transformed_df\n",
    "                    # input = transformed_df\n",
    "                    # self.attribute_ls[d] = self.column_enc_dicts_ls[d][input.iloc[k,d]]\n",
    "                    # del input\n",
    "                    # print(f\"{self.attribute_ls = }\")\n",
    "                    # print(f\"smallc: {smallc}\")\n",
    "                    # self.buc_implementation(input.iloc[k:k+smallc,:], dim=d+1, iteration_num=iteration_num+1)\n",
    "                    self.populate_attribute_ls(k, d, iteration_num)\n",
    "                    self.buc_implementation(slice_range = [k,k+smallc], dim=d+1, iteration_num=iteration_num+1)\n",
    "                    # if self.debug_counter == 10:\n",
    "                        # return {}\n",
    "                    # print(f\"d inside if condition: {d}\")\n",
    "                    # print(f\"******************************************************************\")\n",
    "                k += smallc\n",
    "            # print(f\"#################################################################\")\n",
    "            # print(f\"ALL:\")\n",
    "            # print(f\"k:{k}, d:{d}\")\n",
    "            self.attribute_ls[d] = \"*\"\n",
    "            # print(f\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57438a6b-78f4-46c5-9102-078041e3e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 'Albania', 1: 'Russia', 2: 'India'}, {0: '2009', 1: '2010', 2: '2011', 3: '2012'}, {0: 'm', 1: 'f'}]\n"
     ]
    }
   ],
   "source": [
    "## Parameter\n",
    "minsup = 1\n",
    "input_df = test_df\n",
    "# print(f\"input_df: {input_df}\")\n",
    "preprocess_obj = preprocess_df()\n",
    "transformed_df, column_enc_dicts_ls = preprocess_obj.encode_attributes(input_df, [*range(0,input_df.shape[1])]) #NOTE: This should be modified as required\n",
    "print(column_enc_dicts_ls)\n",
    "buc_obj = buc_external(transformed_df, column_enc_dicts_ls, minsup)\n",
    "buc_obj.buc_implementation([0,transformed_df.shape[0]], 0, 0)\n",
    "output_dict = buc_obj.output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91ab0272-d725-4306-ab17-39738e300610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sex</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2009</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2009</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2010</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2010</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2011</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2011</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2012</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2012</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Albania</td>\n",
       "      <td>*</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Russia</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Russia</td>\n",
       "      <td>2010</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Russia</td>\n",
       "      <td>2010</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Russia</td>\n",
       "      <td>2012</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Russia</td>\n",
       "      <td>2012</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Russia</td>\n",
       "      <td>*</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>India</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>India</td>\n",
       "      <td>2009</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>India</td>\n",
       "      <td>2009</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>India</td>\n",
       "      <td>2010</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>India</td>\n",
       "      <td>2010</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>India</td>\n",
       "      <td>*</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>*</td>\n",
       "      <td>2009</td>\n",
       "      <td>*</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>*</td>\n",
       "      <td>2009</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>*</td>\n",
       "      <td>2009</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>*</td>\n",
       "      <td>2010</td>\n",
       "      <td>*</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>*</td>\n",
       "      <td>2010</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>*</td>\n",
       "      <td>2010</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>*</td>\n",
       "      <td>2011</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>*</td>\n",
       "      <td>2011</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>*</td>\n",
       "      <td>2012</td>\n",
       "      <td>*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>*</td>\n",
       "      <td>2012</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>f</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country  Year Sex  count\n",
       "0         *     *   *     10\n",
       "1   Albania     *   *      6\n",
       "2   Albania  2009   *      2\n",
       "3   Albania  2009   m      2\n",
       "4   Albania  2010   *      1\n",
       "5   Albania  2010   m      1\n",
       "6   Albania  2011   *      2\n",
       "7   Albania  2011   m      2\n",
       "8   Albania  2012   *      1\n",
       "9   Albania  2012   f      1\n",
       "10  Albania     *   m      5\n",
       "11  Albania     *   f      1\n",
       "12   Russia     *   *      2\n",
       "13   Russia  2010   *      1\n",
       "14   Russia  2010   f      1\n",
       "15   Russia  2012   *      1\n",
       "16   Russia  2012   f      1\n",
       "17   Russia     *   f      2\n",
       "18    India     *   *      2\n",
       "19    India  2009   *      1\n",
       "20    India  2009   f      1\n",
       "21    India  2010   *      1\n",
       "22    India  2010   f      1\n",
       "23    India     *   f      2\n",
       "24        *  2009   *      3\n",
       "25        *  2009   m      2\n",
       "26        *  2009   f      1\n",
       "27        *  2010   *      3\n",
       "28        *  2010   m      1\n",
       "29        *  2010   f      2\n",
       "30        *  2011   *      2\n",
       "31        *  2011   m      2\n",
       "32        *  2012   *      2\n",
       "33        *  2012   f      2\n",
       "34        *     *   m      5\n",
       "35        *     *   f      5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict_transformed = {}\n",
    "columns_ls = input_df.columns.tolist()\n",
    "for column in columns_ls:\n",
    "    output_dict_transformed[column] = []\n",
    "    output_dict_transformed['count'] = []\n",
    "for tuple_key, value in output_dict.items():\n",
    "    output_dict_transformed['count'].append(value)\n",
    "    for tuple_key_iter in range(0,len(tuple_key)):\n",
    "        output_dict_transformed[columns_ls[tuple_key_iter]].append(tuple_key[tuple_key_iter])\n",
    "# print(f\"{output_dict = }\")\n",
    "# print(f\"{output_dict_transformed = }\")\n",
    "output_df = pd.DataFrame.from_dict(output_dict_transformed)\n",
    "# columns_order = ['country', 'year', 'sex', 'age', 'generation', 'suicides_range', 'population_range', 'gdp_per_year_income_range', 'count']\n",
    "columns_order = ['Country', 'Year', 'Sex', 'count']\n",
    "output_df = output_df.reindex(columns = columns_order)\n",
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
