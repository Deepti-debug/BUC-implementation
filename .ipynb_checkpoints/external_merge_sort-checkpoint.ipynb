{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import shutil\n",
    "import random\n",
    "import copy\n",
    "import tempfile\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def external_merge_sort_implementation(chunk_paths, d, index_dict, file_path):\n",
    "    sorted_chunk_paths = []\n",
    "    index_ls = copy.deepcopy([*index_dict.values()])\n",
    "    output_len_ls = copy.deepcopy([*index_dict.values()])\n",
    "    output_len_idx = 0\n",
    "    output_file = f\"./sorted_file\"\n",
    "    for i_iter, chunk_path in enumerate(chunk_paths):\n",
    "        # print(f\"{chunk_path = }\")\n",
    "        chunk_df = pd.read_pickle(chunk_path)\n",
    "        if i_iter == 0:\n",
    "            df_columns = chunk_df.columns\n",
    "        # print(f\"{chunk_df = }\")\n",
    "        chunk_df_ls = chunk_df.values.tolist()\n",
    "        # print(f\"{chunk_df_ls = }\")\n",
    "        chunk_df_ls.sort(key = lambda x: (x[d]))\n",
    "        # print(f\"{chunk_df_ls = }\")\n",
    "        sorted_chunk_path = f\"./sorted_{chunk_path.split('/')[-1].split('.pkl')[0]}\"\n",
    "        sorted_chunk_df = pd.DataFrame(chunk_df_ls, columns=df_columns)\n",
    "        print(f\"{sorted_chunk_df = }\")\n",
    "        sorted_chunk_df.to_pickle(sorted_chunk_path)\n",
    "        # with open(sorted_chunk_path, 'w', newline='') as sorted_chunk_file:\n",
    "        #     writer = csv.writer(sorted_chunk_file)\n",
    "        #     writer.writerows(chunk_df_ls)\n",
    "        sorted_chunk_paths.append(sorted_chunk_path)\n",
    "\n",
    "    # Merge sorted chunks\n",
    "    output_ls = []\n",
    "    idxs_ls = [0] * len(chunk_paths)\n",
    "    input_ls = []\n",
    "    min_idx = -1\n",
    "    debug_counter = 0\n",
    "    sorted_chunks_path_cpy = copy.deepcopy(sorted_chunk_paths)\n",
    "    while True:\n",
    "        #First iteration\n",
    "        if min_idx == -1:\n",
    "            for sorted_chunk_path in sorted_chunks_path_cpy:\n",
    "                df = pd.read_pickle(sorted_chunk_path)\n",
    "                input_ls.append(df.values.tolist()[idxs_ls[i_iter]])\n",
    "        else:\n",
    "            try:\n",
    "                print(f\"{sorted_chunks_path_cpy = }\")\n",
    "                print(f\"{min_idx = }\")\n",
    "                print(f\"{idxs_ls = }\")\n",
    "                df = pd.read_pickle(sorted_chunks_path_cpy[min_idx])\n",
    "                print(f\"{df = }\")\n",
    "                input_ls.insert(min_idx, df.values.tolist()[idxs_ls[min_idx]])\n",
    "            except Exception as err:\n",
    "                print(f\"Inside except block... {err}\")\n",
    "  \n",
    "        print(f\"{input_ls = }\")\n",
    "        input_arr = np.array(input_ls)\n",
    "        print(f\"{input_arr = }\")\n",
    "        min_idx = np.argmin(input_arr, axis=0)[d]\n",
    "        print(f\"{min_idx = }\")\n",
    "        output_ls.append(input_ls[min_idx])\n",
    "        print(f\"{output_ls = }\")\n",
    "        input_ls.pop(min_idx)\n",
    "        idxs_ls[min_idx] += 1\n",
    "        print(f\"{idxs_ls = }\")\n",
    "\n",
    "        #Writing output\n",
    "        if len(output_ls) >= output_len_ls[output_len_idx]:\n",
    "            print(f\"{output_ls = }\")\n",
    "            print(f\"{output_len_idx = }\")\n",
    "            print(f\"{output_len_ls[output_len_idx] = }\")\n",
    "            sorted_chunk_df = pd.DataFrame(output_ls, columns=df_columns)\n",
    "            sorted_chunk_df.to_pickle(f\"{file_path}{iteration_num}{output_len_idx}.pkl\")\n",
    "            output_ls = []\n",
    "            output_len_idx += 1\n",
    "        \n",
    "        if idxs_ls[min_idx] > (index_ls[min_idx] -1):\n",
    "            print(f\"Inside greater than condition...\")\n",
    "            idxs_ls.pop(min_idx)\n",
    "            sorted_chunks_path_cpy.pop(min_idx)\n",
    "            index_ls.pop(min_idx)\n",
    "            if len(input_ls) == 0:\n",
    "                break \n",
    "            input_ls.pop(min_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_num = 3\n",
      "Original chunk:    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "Original chunk:    Country  Year  Sex\n",
      "4        1     2    0\n",
      "5        1     3    1\n",
      "6        0     1    1\n",
      "Original chunk:    Country  Year  Sex\n",
      "7        0     3    1\n",
      "8        2     0    1\n",
      "9        2     1    1\n",
      "{0: 4, 1: 3, 2: 3}\n",
      "sorted_chunk_df =    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "sorted_chunk_df =    Country  Year  Sex\n",
      "0        0     1    1\n",
      "1        1     2    0\n",
      "2        1     3    1\n",
      "sorted_chunk_df =    Country  Year  Sex\n",
      "0        0     3    1\n",
      "1        2     0    1\n",
      "2        2     1    1\n",
      "\n",
      "input_ls = [[0, 0, 0], [0, 1, 1], [0, 3, 1]]\n",
      "input_arr = array([[0, 0, 0],\n",
      "       [0, 1, 1],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 0, 0]]\n",
      "idxs_ls = [1, 0, 0]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run0', './sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [1, 0, 0]\n",
      "df =    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "input_ls = [[0, 0, 0], [0, 1, 1], [0, 3, 1]]\n",
      "input_arr = array([[0, 0, 0],\n",
      "       [0, 1, 1],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 0, 0], [0, 0, 0]]\n",
      "idxs_ls = [2, 0, 0]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run0', './sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [2, 0, 0]\n",
      "df =    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "input_ls = [[0, 1, 0], [0, 1, 1], [0, 3, 1]]\n",
      "input_arr = array([[0, 1, 0],\n",
      "       [0, 1, 1],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 0, 0], [0, 0, 0], [0, 1, 0]]\n",
      "idxs_ls = [3, 0, 0]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run0', './sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [3, 0, 0]\n",
      "df =    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "input_ls = [[0, 2, 0], [0, 1, 1], [0, 3, 1]]\n",
      "input_arr = array([[0, 2, 0],\n",
      "       [0, 1, 1],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]]\n",
      "idxs_ls = [4, 0, 0]\n",
      "output_ls = [[0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]]\n",
      "output_len_idx = 0\n",
      "output_len_ls[output_len_idx] = 4\n",
      "Inside greater than condition...\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [0, 0]\n",
      "df =    Country  Year  Sex\n",
      "0        0     1    1\n",
      "1        1     2    0\n",
      "2        1     3    1\n",
      "input_ls = [[0, 1, 1], [0, 3, 1]]\n",
      "input_arr = array([[0, 1, 1],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 1, 1]]\n",
      "idxs_ls = [1, 0]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [1, 0]\n",
      "df =    Country  Year  Sex\n",
      "0        0     1    1\n",
      "1        1     2    0\n",
      "2        1     3    1\n",
      "input_ls = [[1, 2, 0], [0, 3, 1]]\n",
      "input_arr = array([[1, 2, 0],\n",
      "       [0, 3, 1]])\n",
      "min_idx = 1\n",
      "output_ls = [[0, 1, 1], [0, 3, 1]]\n",
      "idxs_ls = [1, 1]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 1\n",
      "idxs_ls = [1, 1]\n",
      "df =    Country  Year  Sex\n",
      "0        0     3    1\n",
      "1        2     0    1\n",
      "2        2     1    1\n",
      "input_ls = [[1, 2, 0], [2, 0, 1]]\n",
      "input_arr = array([[1, 2, 0],\n",
      "       [2, 0, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[0, 1, 1], [0, 3, 1], [1, 2, 0]]\n",
      "idxs_ls = [2, 1]\n",
      "output_ls = [[0, 1, 1], [0, 3, 1], [1, 2, 0]]\n",
      "output_len_idx = 1\n",
      "output_len_ls[output_len_idx] = 3\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run1', './sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [2, 1]\n",
      "df =    Country  Year  Sex\n",
      "0        0     1    1\n",
      "1        1     2    0\n",
      "2        1     3    1\n",
      "input_ls = [[1, 3, 1], [2, 0, 1]]\n",
      "input_arr = array([[1, 3, 1],\n",
      "       [2, 0, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[1, 3, 1]]\n",
      "idxs_ls = [3, 1]\n",
      "Inside greater than condition...\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [1]\n",
      "df =    Country  Year  Sex\n",
      "0        0     3    1\n",
      "1        2     0    1\n",
      "2        2     1    1\n",
      "input_ls = [[2, 0, 1]]\n",
      "input_arr = array([[2, 0, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[1, 3, 1], [2, 0, 1]]\n",
      "idxs_ls = [2]\n",
      "\n",
      "sorted_chunks_path_cpy = ['./sorted_iter_run2']\n",
      "min_idx = 0\n",
      "idxs_ls = [2]\n",
      "df =    Country  Year  Sex\n",
      "0        0     3    1\n",
      "1        2     0    1\n",
      "2        2     1    1\n",
      "input_ls = [[2, 1, 1]]\n",
      "input_arr = array([[2, 1, 1]])\n",
      "min_idx = 0\n",
      "output_ls = [[1, 3, 1], [2, 0, 1], [2, 1, 1]]\n",
      "idxs_ls = [3]\n",
      "output_ls = [[1, 3, 1], [2, 0, 1], [2, 1, 1]]\n",
      "output_len_idx = 2\n",
      "output_len_ls[output_len_idx] = 3\n",
      "Inside greater than condition...\n"
     ]
    }
   ],
   "source": [
    "index_dict = {}\n",
    "# index_dict = {0:[0,1,2,3,4], 1:[5,6,7,8,9]}\n",
    "#Randomly split into multiple chunks and test\\\n",
    "split_num = np.random.randint(1,11)\n",
    "# split_num = 4\n",
    "print(f\"{split_num = }\")\n",
    "chunks_path = []\n",
    "split_df = np.array_split(transformed_df, split_num)\n",
    "for i_iter, df in enumerate(split_df):\n",
    "    index_dict[i_iter] = df.shape[0]\n",
    "    print(f\"Original chunk: {df}\")\n",
    "    df.to_pickle(f\"./iter_run{i_iter}.pkl\")\n",
    "    chunks_path.append(f\"./iter_run{i_iter}.pkl\")\n",
    "# chunk_paths = [f\"./iter_run0.pkl\", f\"./iter_run1.pkl\"]\n",
    "# sort_chunks_modif(chunk_paths, 1, index_dict)\n",
    "print(index_dict)\n",
    "sort_chunks_modif(chunks_path, 0, index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:    Country  Year  Sex\n",
      "0        0     0    0\n",
      "1        0     0    0\n",
      "2        0     1    0\n",
      "3        0     2    0\n",
      "1:    Country  Year  Sex\n",
      "0        0     1    1\n",
      "1        0     3    1\n",
      "2        1     2    0\n",
      "2:    Country  Year  Sex\n",
      "0        1     3    1\n",
      "1        2     0    1\n",
      "2        2     1    1\n",
      "3:    Country  Year  Sex\n",
      "0        2     0    1\n",
      "1        2     1    1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for i_iter, pkl_filename in enumerate(sorted(glob.glob(\"/home/vpk/courses/Data Analytics/BUC-implementation/external_merge_sort/merge_sort/fully_sorted_iter_run*\"))):\n",
    "    df = pd.read_pickle(pkl_filename)\n",
    "    print(f\"{i_iter}: {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Year  Sex\n",
       "0        0     0    0\n",
       "1        0     0    0\n",
       "2        0     1    0\n",
       "3        0     2    0\n",
       "4        1     2    0\n",
       "5        1     3    1\n",
       "6        0     1    1\n",
       "7        0     3    1\n",
       "8        2     0    1\n",
       "9        2     1    1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output = [[0, 0, 0], [0, 1, 0], [0, 2, 0], [0, 1, 1], [0, 3, 1], [1, 2, 0], [1, 3, 1], [2, 0, 1], [2, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'sample_preprocessed.csv'\n",
    "output_path = 'sorted_sample_preprocessed.csv' \n",
    "chunk_size=9 # chunk_size=10, but the chunk list stores 11 rows, so I ma gonna make chunk_size=9.\n",
    "\n",
    "# Step 1: Read the input data and divide into chunks\n",
    "chunk_paths = []\n",
    "with open(input_path, 'r') as input_file:\n",
    "    reader = csv.reader(input_file)\n",
    "    header = next(reader)\n",
    "    print(f\"{header = }\")\n",
    "    chunk = [header]\n",
    "    count = 0\n",
    "    \n",
    "    print(\"############ 1 ############ \")\n",
    "    for i_iter, row in enumerate(reader):\n",
    "        # print(f\"{row = }\")\n",
    "        chunk.append(row)\n",
    "        # print(f\"{chunk = }\")\n",
    "        count += 1\n",
    "        '''\n",
    "        chunk_size=10, but the chunk list stores 11 rows, so I am gonna make chunk_size=9.\n",
    "        '''\n",
    "        if count == chunk_size:\n",
    "            chunk_path = f\"./{i_iter}\"\n",
    "            print(f\"{chunk_path = }\")\n",
    "            with open(chunk_path, 'w', newline='') as chunk_file:\n",
    "                writer = csv.writer(chunk_file)\n",
    "                writer.writerows(chunk)\n",
    "            chunk_paths.append(chunk_path)\n",
    "            print(\"############ 2 ############ \")\n",
    "            # print(f\"{header = }\")\n",
    "            # chunk = [header]\n",
    "            print(f\"{chunk = }\")\n",
    "            chunk = []\n",
    "            count = 0\n",
    "    print(\"########################## \")\n",
    "        \n",
    "# Step 2: Sort and merge chunks\n",
    "sort_chunks(chunk_paths, output_path)\n",
    "\n",
    "# Clean up temporary chunk files\n",
    "# for chunk_path in chunk_paths:\n",
    "#     os.remove(chunk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DataFrame for unit testing\n",
    "country_name_ls = ['Albania'] *4 + ['Russia']*2 + ['Albania'] * 2 + ['India']*2\n",
    "year_ls = ['2009', '2009','2010', '2011', '2011', '2012', '2010', '2012', '2009', '2010']\n",
    "# sex_ls = ['m']*4 + ['f']*2 + ['m'] + ['f']*3\n",
    "sex_ls = ['m']*5 + ['f']*5\n",
    "test_df = pd.DataFrame()\n",
    "test_df['Country'] = country_name_ls\n",
    "test_df['Year'] = year_ls\n",
    "test_df['Sex'] = sex_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_df:\n",
    "  '''\n",
    "  Class to preprocess DataFrame\n",
    "  '''\n",
    "  def encode_attributes(self, input_df, column_indices):\n",
    "    transformed_dicts_ls = []\n",
    "    transformed_df = input_df.copy(deep = True)\n",
    "    column_names = transformed_df.columns.tolist()\n",
    "    # print(f\"{column_names = }\")\n",
    "    for col_iter in column_indices:\n",
    "      temp_dict = {}\n",
    "      temp_key = 0\n",
    "      temp_ls = []\n",
    "      column_name = column_names[col_iter]\n",
    "      for col in transformed_df.iloc[:,col_iter].tolist():\n",
    "        if col not in [*temp_dict.keys()]:\n",
    "          temp_dict[col] = temp_key\n",
    "          temp_key += 1\n",
    "        temp_ls.append(temp_dict[col])\n",
    "      dict_inv = {v:k for k,v in temp_dict.items()}\n",
    "      transformed_dicts_ls.append(dict_inv)\n",
    "      transformed_df[column_name] = temp_ls\n",
    "    return transformed_df, transformed_dicts_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = test_df\n",
    "preprocess_obj = preprocess_df()\n",
    "transformed_df, column_enc_dicts_ls = preprocess_obj.encode_attributes(input_df, [*range(0,input_df.shape[1])]) #NOTE: This should be modified as required\n",
    "split_df = np.array_split(transformed_df, 2) #i.e split test_df into 2 chunks\n",
    "for i_iter, df in enumerate(split_df):\n",
    "    df.to_pickle(f\"iter_run{i_iter}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
